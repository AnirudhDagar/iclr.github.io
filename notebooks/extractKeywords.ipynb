{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('../sitedata/papers.json','r') as f:\n",
    "    papers = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [
    "from nltk import word_tokenize, pos_tag, ne_chunk\n",
    "from nltk import RegexpParser\n",
    "from nltk import Tree\n",
    "\n",
    "# Defining a grammar & Parser\n",
    "#<V\\w+>|\n",
    "NP = \"NP: {(<NN\\w?>)+.*<NN\\w?>}\"\n",
    "chunker = RegexpParser(NP)\n",
    "\n",
    "def get_continuous_chunks(text, chunk_func=ne_chunk):\n",
    "    chunked = chunk_func(pos_tag(word_tokenize(text)))\n",
    "    continuous_chunk = []\n",
    "    current_chunk = []\n",
    "\n",
    "    for subtree in chunked:\n",
    "        if type(subtree) == Tree:\n",
    "            current_chunk.append(\" \".join([token for token, pos in subtree.leaves()]))\n",
    "        elif current_chunk:\n",
    "            named_entity = \" \".join(current_chunk)\n",
    "            if named_entity not in continuous_chunk:\n",
    "                continuous_chunk.append(named_entity)\n",
    "                current_chunk = []\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "    return continuous_chunk\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "for key in papers:\n",
    "    p = papers[key]\n",
    "    p['content']['keywords_gen'] = get_continuous_chunks(p['content']['abstract'], chunker.parse)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "data": {
      "text/plain": "{'id': 'HygnDhEtvr',\n 'content': {'title': 'Reinforcement Learning Based Graph-to-Sequence Model for Natural Question Generation',\n  'authors': ['Yu Chen', 'Lingfei Wu', 'Mohammed J. Zaki'],\n  'authorids': ['cheny39@rpi.edu', 'lwu@email.wm.edu', 'zaki@cs.rpi.edu'],\n  'keywords': ['deep learning',\n   'reinforcement learning',\n   'graph neural networks',\n   'natural language processing',\n   'question generation'],\n  'abstract': 'Natural question generation (QG) aims to generate questions from a passage and an answer. Previous works on QG either (i) ignore the rich structure information hidden in text, (ii) solely rely on cross-entropy loss that leads to issues like exposure bias and inconsistency between train/test measurement, or (iii) fail to fully exploit the answer information. To address these limitations, in this paper, we propose a reinforcement learning (RL) based graph-to-sequence (Graph2Seq) model for QG. Our model consists of a Graph2Seq generator with a novel Bidirectional Gated Graph Neural Network based encoder to embed the passage, and a hybrid evaluator with a mixed objective combining both cross-entropy and RL losses to ensure the generation of syntactically and semantically valid text. We also introduce an effective Deep Alignment Network for incorporating the answer information into the passage at both the word and contextual levels. Our model is end-to-end trainable and achieves new state-of-the-art scores, outperforming existing methods by a significant margin on the standard SQuAD benchmark.',\n  'pdf': '/pdf/b848cdc9d93e44c1717b7c9861ca4c9aae15a1f6.pdf',\n  'paperhash': 'chen|reinforcement_learning_based_graphtosequence_model_for_natural_question_generation',\n  'code': 'https://github.com/hugochan/RL-based-Graph2Seq-for-NQG',\n  '_bibtex': '@inproceedings{\\nChen2020Reinforcement,\\ntitle={Reinforcement Learning Based Graph-to-Sequence Model for Natural Question Generation},\\nauthor={Yu Chen and Lingfei Wu and Mohammed J. Zaki},\\nbooktitle={International Conference on Learning Representations},\\nyear={2020},\\nurl={https://openreview.net/forum?id=HygnDhEtvr}\\n}',\n  'full_presentation_video': '',\n  'original_pdf': '/attachment/48ed57d5f9d094876fb62b42dadaada338fd074c.pdf',\n  'appendix': '',\n  'poster': '',\n  'spotlight_video': '',\n  'slides': '',\n  'keywords_gen': ['question generation',\n   'structure information hidden',\n   'exposure bias',\n   'answer information',\n   'reinforcement learning',\n   'Graph2Seq generator',\n   'Bidirectional Gated Graph Neural Network',\n   'Deep Alignment Network',\n   'answer information SQuAD benchmark']},\n 'forum': 'HygnDhEtvr'}"
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex1 = list(papers.values())[3]\n",
    "ex1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [],
   "source": [
    "with open('../sitedata/papers.json', 'w') as f:\n",
    "    json.dump(papers,f)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}