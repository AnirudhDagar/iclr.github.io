<!doctype html>
<html lang="en">
  <head>
    <!-- Required meta tags -->
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

    <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css" integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous">
    <title> ICLR: Mathematical Reasoning in Latent Space </title>
</head>

  <body >
    
<!-- NAV -->

<script src="https://cdn.jsdelivr.net/npm/popper.js@1.16.0/dist/umd/popper.min.js" integrity="sha384-Q6E9RHvbIyZFJoft+2mJbHaEWldlvI9IOYy5n3zV9zzTtmI3UksdQRVvoxMfooAo" crossorigin="anonymous"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.4.1/js/bootstrap.min.js" integrity="sha384-wfSDF2E50Y2D1uUdj0O3uMBJnjuUD4Ih7YwaYd1iqfktj0Uod8GCExl3Og8ifwB6" crossorigin="anonymous"></script>
<link href="https://fonts.googleapis.com/css?family=Lato:400,900&display=swap" rel="stylesheet">

<style>
    body{font-family: 'Lato', sans-serif;}
</style>

<nav class="navbar navbar-expand-lg navbar-light bg-light mr-auto">
  <a class="navbar-brand" href="#">
    <img class="logo" src="https://www.iclr.cc/static/admin/img/ICLR-logo.png"  height="35"/>
  </a>
  <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
    <span class="navbar-toggler-icon"></span>
  </button>
  <div class="collapse navbar-collapse" id="navbarNav">
    <ul class="navbar-nav">
      <li class="nav-item active">
        <a class="nav-link" href="index.html">Home</a>
      </li>
      <li class="nav-item">
        <a class="nav-link" href="livestream.html">Live Stream</a>
      </li>
      <li class="nav-item">
        <a class="nav-link" href="papers.html">Papers</a>
      </li>

      <li class="nav-item">
        <a class="nav-link" href="paper_vis.html">PaperVis</a>
      </li>










      </ul>
</div>
  </div>
</nav>


<div class="container">
  
 <!-- Title -->

<div class="card" >
  <div class="card-body">
    <h3 class="card-title">Mathematical Reasoning in Latent Space</h3>
    <h6 class="card-subtitle mb-2 text-muted">
      Dennis Lee,
      
      Christian Szegedy,
      
      Markus Rabe,
      
      Sarah Loos,
      
      Kshitij Bansal,
      
    </h6>
    <p class="card-text"><span class="font-weight-bold">TL;DR:</span> Learning to reason about higher order logic formulas in the latent space.</p>
    <p class="card-text"><span class="font-weight-bold">Abstract:</span> We design and conduct a simple experiment to study whether neural networks can perform several steps of approximate reasoning in a fixed dimensional latent space. The set of rewrites (i.e. transformations) that can be successfully performed on a statement represents essential semantic features of the statement. We can compress this information by embedding the formula in a vector space, such that the vector associated with a statement can be used to predict whether a statement can be rewritten by other theorems. Predicting the embedding of a formula generated by some rewrite rule is naturally viewed as approximate reasoning in the latent space. In order to measure the effectiveness of this reasoning, we perform approximate deduction sequences in the latent space and use the resulting embedding to inform the semantic features of the corresponding formal statement (which is obtained by performing the corresponding rewrite sequence using real formulas). Our experiments show that graph neural networks can make non-trivial predictions about the rewrite-success of statements, even when they propagate predicted latent representations for several steps. Since our corpus of mathematical formulas includes a wide variety of mathematical disciplines, this experiment is a strong indicator for the feasibility of deduction in latent space in general.</p>
    
    <center>
      <a class="card-link"  href="http://www.openreview.net/pdf/7f1f2bf386393e98651939a6b7fab8f4fdb99341.pdf">Paper</a>
      <a class="card-link"  href="http://www.openreview.net/forum?id=Ske31kBtPr">OpenReview</a>
    <!-- <span><a href="" class="btn btn-secondary">OpenReview</a></span> -->

      <a href="" class="card-link">Code</a>
      <a href="" class="card-link">Slides</a>
    </center>
    <p></p>
    <p class="card-text"><span class="font-weight-bold">Keywords:</span>
      
      <a href="keyword_machine learning.html" class="text-secondary text-decoration-none">machine learning</a>,
      
      <a href="keyword_formal reasoning.html" class="text-secondary text-decoration-none">formal reasoning</a>,
      
    </p>    
  </div>
</div>

<div>
</div>

</div>


<!-- SlidesLive -->
<div id="presentation-embed-38915748" class="container container-sm"></div>
<script src='https://slideslive.com/embed_presentation.js'></script>
<script>
  embed = new SlidesLiveEmbed('presentation-embed-38915748', {
        presentationId: '38915748',
        autoPlay: false, // change to true to autoplay the embedded presentation
        verticalEnabled: true
    });
</script>


<!-- Buttons -->
<div  class="container" style="padding-bottom: 30px; padding-top:30px">
<!--   <center> -->
<!--     <span><a href="poster_.html" class="btn btn-secondary">Prev</a></span> -->

<!--     <span><a href="" class="btn btn-secondary">Video Call</a></span> -->

<!--     <span><a href="poster_.html" class="btn btn-secondary">Next</a></span> </center> -->
<!-- </div> -->
<!--   <center> -->
<center>
    <h2> Paper Discussion       </h2>
    <span><a class="btn btn-secondary" href="https://gitter.im/iclr/posterSke31kBtPr/">Chat</a></span>
</center>
<p></p>
<!-- Gitter -->
<div id="gitter" class="gitter container" height="600px">
  <center>
    <div class="border">
      <center> <iframe frameborder="0" src="https://gitter.im/iclr/posterSke31kBtPr/~embed" width="900px" height="400px"></iframe> </center>
    </div>
  </center>
</div>

<!-- Recs -->
<p></p>
<div  class="container" style="padding-bottom: 30px; padding-top:30px">
  <center>
    <h2> Similar Papers </h2>
</div>
<p></p>

<div  class="container" >
  <div class="row">
    <div class="card-deck">

      
      
  <!-- <div class="col-sm-4" style="padding-bottom: 10px"> -->
  <div class="card" >
    <div class="card-header">
        <a href="poster_rygeHgSFDH.html" class="text-dark"><h5 class="card-title">Disentanglement by Nonlinear ICA with General Incompressible-flow Networks (GIN)</h5></a>      

    </div>
      <div class="card-body">
        <p class="card-text"> A central question of representation learning asks under which conditions it is possible to reconstruct the true latent variables of an arbitrarily complex generative process. Recent breakthrough work by Khemakhem et al. (2019) on nonlinear ICA has a...</p>
      </div>
      
      <div class="card-footer">
      <center>
        <a href="poster_rygeHgSFDH.html" class="btn btn-primary">Visit</a>
        </center>

      </div>
      <!-- </div> -->

  </div>
  
      
  <!-- <div class="col-sm-4" style="padding-bottom: 10px"> -->
  <div class="card" >
    <div class="card-header">
        <a href="poster_H1laeJrKDB.html" class="text-dark"><h5 class="card-title">Controlling generative models with continuous factors of variations</h5></a>      

    </div>
      <div class="card-body">
        <p class="card-text"> A model to control the generation of images with GAN and beta-VAE with regard to scale and position of the objects</p>
      </div>
      
      <div class="card-footer">
      <center>
        <a href="poster_H1laeJrKDB.html" class="btn btn-primary">Visit</a>
        </center>

      </div>
      <!-- </div> -->

  </div>
  
      
  <!-- <div class="col-sm-4" style="padding-bottom: 10px"> -->
  <div class="card" >
    <div class="card-header">
        <a href="poster_S1g6xeSKDS.html" class="text-dark"><h5 class="card-title">Mixed-curvature Variational Autoencoders</h5></a>      

    </div>
      <div class="card-body">
        <p class="card-text"> Variational Autoencoders with latent spaces modeled as products of constant curvature Riemannian manifolds improve on image reconstruction over single-manifold variants.</p>
      </div>
      
      <div class="card-footer">
      <center>
        <a href="poster_S1g6xeSKDS.html" class="btn btn-primary">Visit</a>
        </center>

      </div>
      <!-- </div> -->

  </div>
  
      
  <!-- <div class="col-sm-4" style="padding-bottom: 10px"> -->
  <div class="card" >
    <div class="card-header">
        <a href="poster_BJxG_0EtDS.html" class="text-dark"><h5 class="card-title">Prediction, Consistency, Curvature: Representation Learning for Locally-Linear Control</h5></a>      

    </div>
      <div class="card-body">
        <p class="card-text"> Learning embedding for control with high-dimensional observations</p>
      </div>
      
      <div class="card-footer">
      <center>
        <a href="poster_BJxG_0EtDS.html" class="btn btn-primary">Visit</a>
        </center>

      </div>
      <!-- </div> -->

  </div>
  
    </DIV>
          </DIV>
      </DIV>

</body>