<!doctype html>
<html lang="en">
  <head>
    <!-- Required meta tags -->
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

    <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css" integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous">
    <title> ICLR: Accelerating SGD with momentum for over-parameterized learning </title>
</head>

  <body >
    
<!-- NAV -->

<script src="https://cdn.jsdelivr.net/npm/popper.js@1.16.0/dist/umd/popper.min.js" integrity="sha384-Q6E9RHvbIyZFJoft+2mJbHaEWldlvI9IOYy5n3zV9zzTtmI3UksdQRVvoxMfooAo" crossorigin="anonymous"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.4.1/js/bootstrap.min.js" integrity="sha384-wfSDF2E50Y2D1uUdj0O3uMBJnjuUD4Ih7YwaYd1iqfktj0Uod8GCExl3Og8ifwB6" crossorigin="anonymous"></script>
<link href="https://fonts.googleapis.com/css?family=Lato:400,900&display=swap" rel="stylesheet">

<style>
    body{font-family: 'Lato', sans-serif;}
</style>

<nav class="navbar navbar-expand-lg navbar-light bg-light mr-auto">
  <a class="navbar-brand" href="#">
    <img class="logo" src="https://www.iclr.cc/static/admin/img/ICLR-logo.png"  height="35"/>
  </a>
  <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
    <span class="navbar-toggler-icon"></span>
  </button>
  <div class="collapse navbar-collapse" id="navbarNav">
    <ul class="navbar-nav">
      <li class="nav-item active">
        <a class="nav-link" href="index.html">Home</a>
      </li>
      <li class="nav-item">
        <a class="nav-link" href="livestream.html">Live Stream</a>
      </li>
      <li class="nav-item">
        <a class="nav-link" href="papers.html">Papers</a>
      </li>

      <li class="nav-item">
        <a class="nav-link" href="paper_vis.html">PaperVis</a>
      </li>










      </ul>
</div>
  </div>
</nav>


<div class="container">
  
 <!-- Title -->

<div class="card" >
  <div class="card-body">
    <h3 class="card-title">Accelerating SGD with momentum for over-parameterized learning</h3>
    <h6 class="card-subtitle mb-2 text-muted">
      Chaoyue Liu,
      
      Mikhail Belkin,
      
    </h6>
    <p class="card-text"><span class="font-weight-bold">TL;DR:</span> This work proves the non-acceleration of Nesterov SGD with any hyper-parameters, and proposes new algorithm which provably accelerates SGD in the over-parameterized setting.</p>
    <p class="card-text"><span class="font-weight-bold">Abstract:</span> 
Nesterov SGD is widely used for training modern neural networks and other machine learning models. Yet, its advantages over SGD have not been theoretically clarified. Indeed, as we show  in this paper, both theoretically and empirically, Nesterov SGD with any parameter selection does not in general provide acceleration over ordinary SGD. Furthermore, Nesterov SGD may diverge for step sizes that ensure convergence of ordinary SGD. This is in contrast to the classical results in the deterministic setting, where the same step size ensures accelerated convergence of the Nesterov&#39;s method over optimal gradient descent.

To address the non-acceleration issue, we  introduce a compensation term to Nesterov SGD. The resulting  algorithm, which we call MaSS, converges  for same step sizes as SGD. We prove that MaSS obtains an accelerated convergence rates over SGD for any mini-batch size in the linear setting.  For full batch, the convergence rate of MaSS matches the well-known accelerated rate of the Nesterov&#39;s method. 

We also analyze the  practically important question of the dependence of the convergence rate and  optimal hyper-parameters on the mini-batch size, demonstrating three distinct regimes: linear scaling, diminishing returns and saturation.

Experimental evaluation of MaSS for several standard  architectures of deep networks, including ResNet and convolutional networks, shows improved performance over SGD, Nesterov SGD  and Adam. </p>
    
    <center>
      <a class="card-link"  href="http://www.openreview.net/pdf/67006b8932120072903be0eb7bfca6fc324e26c6.pdf">Paper</a>
      <a class="card-link"  href="http://www.openreview.net/forum?id=r1gixp4FPH">OpenReview</a>
    <!-- <span><a href="" class="btn btn-secondary">OpenReview</a></span> -->

      <a href="https://github.com/ts66395/MaSS" class="card-link">Code</a>
      <a href="" class="card-link">Slides</a>
    </center>
    <p></p>
    <p class="card-text"><span class="font-weight-bold">Keywords:</span>
      
      <a href="keyword_SGD.html" class="text-secondary text-decoration-none">SGD</a>,
      
      <a href="keyword_acceleration.html" class="text-secondary text-decoration-none">acceleration</a>,
      
      <a href="keyword_momentum.html" class="text-secondary text-decoration-none">momentum</a>,
      
      <a href="keyword_stochastic.html" class="text-secondary text-decoration-none">stochastic</a>,
      
      <a href="keyword_over-parameterized.html" class="text-secondary text-decoration-none">over-parameterized</a>,
      
      <a href="keyword_Nesterov.html" class="text-secondary text-decoration-none">Nesterov</a>,
      
    </p>    
  </div>
</div>

<div>
</div>

</div>


<!-- SlidesLive -->
<div id="presentation-embed-38915748" class="container container-sm"></div>
<script src='https://slideslive.com/embed_presentation.js'></script>
<script>
  embed = new SlidesLiveEmbed('presentation-embed-38915748', {
        presentationId: '38915748',
        autoPlay: false, // change to true to autoplay the embedded presentation
        verticalEnabled: true
    });
</script>


<!-- Buttons -->
<div  class="container" style="padding-bottom: 30px; padding-top:30px">
<!--   <center> -->
<!--     <span><a href="poster_.html" class="btn btn-secondary">Prev</a></span> -->

<!--     <span><a href="" class="btn btn-secondary">Video Call</a></span> -->

<!--     <span><a href="poster_.html" class="btn btn-secondary">Next</a></span> </center> -->
<!-- </div> -->
<!--   <center> -->
<center>
    <h2> Paper Discussion       </h2>
    <span><a class="btn btn-secondary" href="https://gitter.im/iclr/posterr1gixp4FPH/">Chat</a></span>
</center>
<p></p>
<!-- Gitter -->
<div id="gitter" class="gitter container" height="600px">
  <center>
    <div class="border">
      <center> <iframe frameborder="0" src="https://gitter.im/iclr/posterr1gixp4FPH/~embed" width="900px" height="400px"></iframe> </center>
    </div>
  </center>
</div>

<!-- Recs -->
<p></p>
<div  class="container" style="padding-bottom: 30px; padding-top:30px">
  <center>
    <h2> Similar Papers </h2>
</div>
<p></p>

<div  class="container" >
  <div class="row">
    <div class="card-deck">

      
      
  <!-- <div class="col-sm-4" style="padding-bottom: 10px"> -->
  <div class="card" >
    <div class="card-header">
        <a href="poster_rkeNfp4tPr.html" class="text-dark"><h5 class="card-title">Escaping Saddle Points Faster with Stochastic Momentum</h5></a>      

    </div>
      <div class="card-body">
        <p class="card-text"> Higher momentum parameter $\beta$ helps for escaping saddle points faster</p>
      </div>
      
      <div class="card-footer">
      <center>
        <a href="poster_rkeNfp4tPr.html" class="btn btn-primary">Visit</a>
        </center>

      </div>
      <!-- </div> -->

  </div>
  
      
  <!-- <div class="col-sm-4" style="padding-bottom: 10px"> -->
  <div class="card" >
    <div class="card-header">
        <a href="poster_B1eyO1BFPr.html" class="text-dark"><h5 class="card-title">Don&#39;t Use Large Mini-batches, Use Local SGD</h5></a>      

    </div>
      <div class="card-body">
        <p class="card-text"> Mini-batch stochastic gradient methods (SGD) are state of the art for distributed training of deep neural networks. 
Drastic increases in the mini-batch sizes have lead to key efficiency and scalability gains in recent years. 
However, progress faces...</p>
      </div>
      
      <div class="card-footer">
      <center>
        <a href="poster_B1eyO1BFPr.html" class="btn btn-primary">Visit</a>
        </center>

      </div>
      <!-- </div> -->

  </div>
  
      
  <!-- <div class="col-sm-4" style="padding-bottom: 10px"> -->
  <div class="card" >
    <div class="card-header">
        <a href="poster_HJxEhREKDH.html" class="text-dark"><h5 class="card-title">On the Global Convergence  of Training Deep Linear ResNets</h5></a>      

    </div>
      <div class="card-body">
        <p class="card-text"> Under certain condition on the input and output linear transformations, both GD and SGD can achieve global convergence for training deep linear ResNets.</p>
      </div>
      
      <div class="card-footer">
      <center>
        <a href="poster_HJxEhREKDH.html" class="btn btn-primary">Visit</a>
        </center>

      </div>
      <!-- </div> -->

  </div>
  
      
  <!-- <div class="col-sm-4" style="padding-bottom: 10px"> -->
  <div class="card" >
    <div class="card-header">
        <a href="poster_r1g87C4KwB.html" class="text-dark"><h5 class="card-title">The Break-Even Point on Optimization Trajectories of Deep Neural Networks</h5></a>      

    </div>
      <div class="card-body">
        <p class="card-text"> In the early phase of training of deep neural networks there exists a &#34;break-even point&#34; which determines properties of the entire optimization trajectory.</p>
      </div>
      
      <div class="card-footer">
      <center>
        <a href="poster_r1g87C4KwB.html" class="btn btn-primary">Visit</a>
        </center>

      </div>
      <!-- </div> -->

  </div>
  
    </DIV>
          </DIV>
      </DIV>

</body>