<!doctype html>
<html lang="en">
  <head>
    <!-- Required meta tags -->
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

    <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css" integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous">
    <title> ICLR: Learning Efficient Parameter Server Synchronization Policies for Distributed SGD </title>
</head>

  <body >
    
<!-- NAV -->

<script src="https://cdn.jsdelivr.net/npm/popper.js@1.16.0/dist/umd/popper.min.js" integrity="sha384-Q6E9RHvbIyZFJoft+2mJbHaEWldlvI9IOYy5n3zV9zzTtmI3UksdQRVvoxMfooAo" crossorigin="anonymous"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.4.1/js/bootstrap.min.js" integrity="sha384-wfSDF2E50Y2D1uUdj0O3uMBJnjuUD4Ih7YwaYd1iqfktj0Uod8GCExl3Og8ifwB6" crossorigin="anonymous"></script>
<link href="https://fonts.googleapis.com/css?family=Lato:400,900&display=swap" rel="stylesheet">

<style>
    body{font-family: 'Lato', sans-serif;}
</style>

<nav class="navbar navbar-expand-lg navbar-light bg-light mr-auto">
  <a class="navbar-brand" href="#">
    <img class="logo" src="https://www.iclr.cc/static/admin/img/ICLR-logo.png"  height="35"/>
  </a>
  <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
    <span class="navbar-toggler-icon"></span>
  </button>
  <div class="collapse navbar-collapse" id="navbarNav">
    <ul class="navbar-nav">
      <li class="nav-item active">
        <a class="nav-link" href="index.html">Home</a>
      </li>
      <li class="nav-item">
        <a class="nav-link" href="livestream.html">Live Stream</a>
      </li>
      <li class="nav-item">
        <a class="nav-link" href="papers.html">Papers</a>
      </li>

      <li class="nav-item">
        <a class="nav-link" href="paper_vis.html">PaperVis</a>
      </li>










      </ul>
</div>
  </div>
</nav>


<div class="container">
  
 <!-- Title -->

<div class="card" >
  <div class="card-body">
    <h3 class="card-title">Learning Efficient Parameter Server Synchronization Policies for Distributed SGD</h3>
    <h6 class="card-subtitle mb-2 text-muted">
      Rong Zhu,
      
      Sheng Yang,
      
      Andreas Pfadler,
      
      Zhengping Qian,
      
      Jingren Zhou,
      
    </h6>
    <p class="card-text"><span class="font-weight-bold">TL;DR:</span> We apply a reinforcement learning based approach to learning optimal synchronization policies used for Parameter Server-based distributed training  of SGD.</p>
    <p class="card-text"><span class="font-weight-bold">Abstract:</span> We apply a reinforcement learning (RL) based approach to learning optimal synchronization policies used for Parameter Server-based distributed training of machine learning models with Stochastic Gradient Descent (SGD). Utilizing a formal synchronization policy description in the PS-setting, we are able to derive a suitable and compact description of states and actions, allowing us to efficiently use the standard off-the-shelf deep Q-learning algorithm. As a result, we are able to learn synchronization policies which generalize to different cluster environments, different training datasets and small model variations and (most importantly) lead to considerable decreases in training time when compared to standard policies such as bulk synchronous parallel (BSP), asynchronous parallel (ASP), or stale synchronous parallel (SSP). To support our claims we present extensive numerical results obtained from experiments performed in simulated cluster environments. In our experiments training time is reduced by 44 on average and learned policies generalize to multiple unseen circumstances.</p>
    
    <center>
      <a class="card-link"  href="http://www.openreview.net/pdf/fc39ecda92e2e29f172b0a5a9cf95c58c0c2246c.pdf">Paper</a>
      <a class="card-link"  href="http://www.openreview.net/forum?id=rJxX8T4Kvr">OpenReview</a>
    <!-- <span><a href="" class="btn btn-secondary">OpenReview</a></span> -->

      <a href="" class="card-link">Code</a>
      <a href="" class="card-link">Slides</a>
    </center>
    <p></p>
    <p class="card-text"><span class="font-weight-bold">Keywords:</span>
      
      <a href="keyword_Distributed SGD.html" class="text-secondary text-decoration-none">Distributed SGD</a>,
      
      <a href="keyword_Paramter-Server.html" class="text-secondary text-decoration-none">Paramter-Server</a>,
      
      <a href="keyword_Synchronization Policy.html" class="text-secondary text-decoration-none">Synchronization Policy</a>,
      
      <a href="keyword_Reinforcement Learning.html" class="text-secondary text-decoration-none">Reinforcement Learning</a>,
      
    </p>    
  </div>
</div>

<div>
</div>

</div>


<!-- SlidesLive -->
<div id="presentation-embed-38915748" class="container container-sm"></div>
<script src='https://slideslive.com/embed_presentation.js'></script>
<script>
  embed = new SlidesLiveEmbed('presentation-embed-38915748', {
        presentationId: '38915748',
        autoPlay: false, // change to true to autoplay the embedded presentation
        verticalEnabled: true
    });
</script>


<!-- Buttons -->
<div  class="container" style="padding-bottom: 30px; padding-top:30px">
<!--   <center> -->
<!--     <span><a href="poster_.html" class="btn btn-secondary">Prev</a></span> -->

<!--     <span><a href="" class="btn btn-secondary">Video Call</a></span> -->

<!--     <span><a href="poster_.html" class="btn btn-secondary">Next</a></span> </center> -->
<!-- </div> -->
<!--   <center> -->
<center>
    <h2> Paper Discussion       </h2>
    <span><a class="btn btn-secondary" href="https://gitter.im/iclr/posterrJxX8T4Kvr/">Chat</a></span>
</center>
<p></p>
<!-- Gitter -->
<div id="gitter" class="gitter container" height="600px">
  <center>
    <div class="border">
      <center> <iframe frameborder="0" src="https://gitter.im/iclr/posterrJxX8T4Kvr/~embed" width="900px" height="400px"></iframe> </center>
    </div>
  </center>
</div>

<!-- Recs -->
<p></p>
<div  class="container" style="padding-bottom: 30px; padding-top:30px">
  <center>
    <h2> Similar Papers </h2>
</div>
<p></p>

<div  class="container" >
  <div class="row">
    <div class="card-deck">

      
      
  <!-- <div class="col-sm-4" style="padding-bottom: 10px"> -->
  <div class="card" >
    <div class="card-header">
        <a href="poster_S1l8oANFDH.html" class="text-dark"><h5 class="card-title">Synthesizing Programmatic Policies that Inductively Generalize</h5></a>      

    </div>
      <div class="card-body">
        <p class="card-text"> An approach to learn program policies for control tasks that inductively generalize. </p>
      </div>
      
      <div class="card-footer">
      <center>
        <a href="poster_S1l8oANFDH.html" class="btn btn-primary">Visit</a>
        </center>

      </div>
      <!-- </div> -->

  </div>
  
      
  <!-- <div class="col-sm-4" style="padding-bottom: 10px"> -->
  <div class="card" >
    <div class="card-header">
        <a href="poster_Sye57xStvB.html" class="text-dark"><h5 class="card-title">Never Give Up: Learning Directed Exploration Strategies</h5></a>      

    </div>
      <div class="card-body">
        <p class="card-text"> We propose a reinforcement learning agent to solve hard exploration games by learning a range of directed exploratory policies. </p>
      </div>
      
      <div class="card-footer">
      <center>
        <a href="poster_Sye57xStvB.html" class="btn btn-primary">Visit</a>
        </center>

      </div>
      <!-- </div> -->

  </div>
  
      
  <!-- <div class="col-sm-4" style="padding-bottom: 10px"> -->
  <div class="card" >
    <div class="card-header">
        <a href="poster_H1ezFREtwH.html" class="text-dark"><h5 class="card-title">Composing Task-Agnostic Policies with Deep Reinforcement Learning</h5></a>      

    </div>
      <div class="card-body">
        <p class="card-text"> We propose a novel reinforcement learning-based skill transfer and composition method that takes the agent&#39;s primitive policies to solve unseen tasks.</p>
      </div>
      
      <div class="card-footer">
      <center>
        <a href="poster_H1ezFREtwH.html" class="btn btn-primary">Visit</a>
        </center>

      </div>
      <!-- </div> -->

  </div>
  
      
  <!-- <div class="col-sm-4" style="padding-bottom: 10px"> -->
  <div class="card" >
    <div class="card-header">
        <a href="poster_HJgcvJBFvB.html" class="text-dark"><h5 class="card-title">Network Randomization: A Simple Technique for Generalization in Deep Reinforcement Learning</h5></a>      

    </div>
      <div class="card-body">
        <p class="card-text"> We propose a simple randomization technique for improving generalization in deep reinforcement learning across tasks with various unseen visual patterns.</p>
      </div>
      
      <div class="card-footer">
      <center>
        <a href="poster_HJgcvJBFvB.html" class="btn btn-primary">Visit</a>
        </center>

      </div>
      <!-- </div> -->

  </div>
  
    </DIV>
          </DIV>
      </DIV>

</body>