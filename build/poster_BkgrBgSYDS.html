<!doctype html>
<html lang="en">
  <head>
    <!-- Required meta tags -->
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

    <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css" integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous">
    <title> ICLR: Kaleidoscope: An Efficient, Learnable Representation For All Structured Linear Maps </title>
</head>

  <body >
    
<!-- NAV -->

<script src="https://cdn.jsdelivr.net/npm/popper.js@1.16.0/dist/umd/popper.min.js" integrity="sha384-Q6E9RHvbIyZFJoft+2mJbHaEWldlvI9IOYy5n3zV9zzTtmI3UksdQRVvoxMfooAo" crossorigin="anonymous"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.4.1/js/bootstrap.min.js" integrity="sha384-wfSDF2E50Y2D1uUdj0O3uMBJnjuUD4Ih7YwaYd1iqfktj0Uod8GCExl3Og8ifwB6" crossorigin="anonymous"></script>
<link href="https://fonts.googleapis.com/css?family=Lato:400,900&display=swap" rel="stylesheet">

<style>
    body{font-family: 'Lato', sans-serif;}
</style>

<nav class="navbar navbar-expand-lg navbar-light bg-light mr-auto">
  <a class="navbar-brand" href="#">
    <img class="logo" src="https://www.iclr.cc/static/admin/img/ICLR-logo.png"  height="35"/>
  </a>
  <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
    <span class="navbar-toggler-icon"></span>
  </button>
  <div class="collapse navbar-collapse" id="navbarNav">
    <ul class="navbar-nav">
      <li class="nav-item active">
        <a class="nav-link" href="index.html">Home</a>
      </li>
      <li class="nav-item">
        <a class="nav-link" href="livestream.html">Live Stream</a>
      </li>
      <li class="nav-item">
        <a class="nav-link" href="papers.html">Papers</a>
      </li>

      <li class="nav-item">
        <a class="nav-link" href="paper_vis.html">PaperVis</a>
      </li>










      </ul>
</div>
  </div>
</nav>


<div class="container">
  
 <!-- Title -->

<div class="card" >
  <div class="card-body">
    <h3 class="card-title">Kaleidoscope: An Efficient, Learnable Representation For All Structured Linear Maps</h3>
    <h6 class="card-subtitle mb-2 text-muted">
      Tri Dao,
      
      Nimit Sohoni,
      
      Albert Gu,
      
      Matthew Eichhorn,
      
      Amit Blonder,
      
      Megan Leszczynski,
      
      Atri Rudra,
      
      Christopher RÃ©,
      
    </h6>
    <p class="card-text"><span class="font-weight-bold">TL;DR:</span> We propose a differentiable family of &#34;kaleidoscope matrices,&#34; prove that all structured matrices can be represented in this form, and use them to replace hand-crafted linear maps in deep learning models.</p>
    <p class="card-text"><span class="font-weight-bold">Abstract:</span> Modern neural network architectures use structured linear transformations, such as low-rank matrices, sparse matrices, permutations, and the Fourier transform, to improve inference speed and reduce memory usage compared to general linear maps. However, choosing which of the myriad structured transformations to use (and its associated parameterization) is a laborious task that requires trading off speed, space, and accuracy. We consider a different approach: we introduce a family of matrices called kaleidoscope matrices (K-matrices) that provably capture any structured matrix with near-optimal space (parameter) and time (arithmetic operation) complexity. We empirically validate that K-matrices can be automatically learned within end-to-end pipelines to replace hand-crafted procedures, in order to improve model quality. For example, replacing channel shuffles in ShuffleNet improves classification accuracy on ImageNet by up to 5%. K-matrices can also simplify hand-engineered pipelines---we replace filter bank feature computation in speech data preprocessing with a learnable kaleidoscope layer, resulting in only 0.4% loss in accuracy on the TIMIT speech recognition task. In addition, K-matrices can capture latent structure in models: for a challenging permuted image classification task, adding a K-matrix to a standard convolutional architecture can enable learning the latent permutation and improve accuracy by over 8 points. We provide a practically efficient implementation of our approach, and use K-matrices in a Transformer network to attain 36% faster end-to-end inference speed on a language translation task.</p>
    
    <center>
      <a class="card-link"  href="http://www.openreview.net/pdf/e6c98a4caacf05eb4e3066b934931be05b8162f4.pdf">Paper</a>
      <a class="card-link"  href="http://www.openreview.net/forum?id=BkgrBgSYDS">OpenReview</a>
    <!-- <span><a href="" class="btn btn-secondary">OpenReview</a></span> -->

      <a href="https://github.com/HazyResearch/learning-circuits" class="card-link">Code</a>
      <a href="" class="card-link">Slides</a>
    </center>
    <p></p>
    <p class="card-text"><span class="font-weight-bold">Keywords:</span>
      
      <a href="keyword_structured matrices.html" class="text-secondary text-decoration-none">structured matrices</a>,
      
      <a href="keyword_efficient ML.html" class="text-secondary text-decoration-none">efficient ML</a>,
      
      <a href="keyword_algorithms.html" class="text-secondary text-decoration-none">algorithms</a>,
      
      <a href="keyword_butterfly matrices.html" class="text-secondary text-decoration-none">butterfly matrices</a>,
      
      <a href="keyword_arithmetic circuits.html" class="text-secondary text-decoration-none">arithmetic circuits</a>,
      
    </p>    
  </div>
</div>

<div>
</div>

</div>


<!-- SlidesLive -->
<div id="presentation-embed-38915748" class="container container-sm"></div>
<script src='https://slideslive.com/embed_presentation.js'></script>
<script>
  embed = new SlidesLiveEmbed('presentation-embed-38915748', {
        presentationId: '38915748',
        autoPlay: false, // change to true to autoplay the embedded presentation
        verticalEnabled: true
    });
</script>


<!-- Buttons -->
<div  class="container" style="padding-bottom: 30px; padding-top:30px">
<!--   <center> -->
<!--     <span><a href="poster_.html" class="btn btn-secondary">Prev</a></span> -->

<!--     <span><a href="" class="btn btn-secondary">Video Call</a></span> -->

<!--     <span><a href="poster_.html" class="btn btn-secondary">Next</a></span> </center> -->
<!-- </div> -->
<!--   <center> -->
<center>
    <h2> Paper Discussion       </h2>
    <span><a class="btn btn-secondary" href="https://gitter.im/iclr/posterBkgrBgSYDS/">Chat</a></span>
</center>
<p></p>
<!-- Gitter -->
<div id="gitter" class="gitter container" height="600px">
  <center>
    <div class="border">
      <center> <iframe frameborder="0" src="https://gitter.im/iclr/posterBkgrBgSYDS/~embed" width="900px" height="400px"></iframe> </center>
    </div>
  </center>
</div>

<!-- Recs -->
<p></p>
<div  class="container" style="padding-bottom: 30px; padding-top:30px">
  <center>
    <h2> Similar Papers </h2>
</div>
<p></p>

<div  class="container" >
  <div class="row">
    <div class="card-deck">

      
      
  <!-- <div class="col-sm-4" style="padding-bottom: 10px"> -->
  <div class="card" >
    <div class="card-header">
        <a href="poster_SJem8lSFwB.html" class="text-dark"><h5 class="card-title">Dynamic Model Pruning with Feedback</h5></a>      

    </div>
      <div class="card-body">
        <p class="card-text"> Deep neural networks often have millions of parameters. This can hinder their deployment to low-end devices, not only due to high memory requirements but also because of increased latency at inference. We propose a novel model compression method that...</p>
      </div>
      
      <div class="card-footer">
      <center>
        <a href="poster_SJem8lSFwB.html" class="btn btn-primary">Visit</a>
        </center>

      </div>
      <!-- </div> -->

  </div>
  
      
  <!-- <div class="col-sm-4" style="padding-bottom: 10px"> -->
  <div class="card" >
    <div class="card-header">
        <a href="poster_HyxjOyrKvr.html" class="text-dark"><h5 class="card-title">Neural Epitome Search for Architecture-Agnostic Network Compression</h5></a>      

    </div>
      <div class="card-body">
        <p class="card-text"> We present a novel neural network compression method which can reuse the parameters efficiently to reduce the model size.</p>
      </div>
      
      <div class="card-footer">
      <center>
        <a href="poster_HyxjOyrKvr.html" class="btn btn-primary">Visit</a>
        </center>

      </div>
      <!-- </div> -->

  </div>
  
      
  <!-- <div class="col-sm-4" style="padding-bottom: 10px"> -->
  <div class="card" >
    <div class="card-header">
        <a href="poster_HkgxW0EYDS.html" class="text-dark"><h5 class="card-title">Scalable Model Compression by Entropy Penalized Reparameterization</h5></a>      

    </div>
      <div class="card-body">
        <p class="card-text"> An end-to-end trainable model compression method optimizing accuracy jointly with the expected model size.</p>
      </div>
      
      <div class="card-footer">
      <center>
        <a href="poster_HkgxW0EYDS.html" class="btn btn-primary">Visit</a>
        </center>

      </div>
      <!-- </div> -->

  </div>
  
      
  <!-- <div class="col-sm-4" style="padding-bottom: 10px"> -->
  <div class="card" >
    <div class="card-header">
        <a href="poster_rkeu30EtvS.html" class="text-dark"><h5 class="card-title">Network Deconvolution</h5></a>      

    </div>
      <div class="card-body">
        <p class="card-text"> We propose a method called network deconvolution that resembles animal vision system to train convolution networks better.</p>
      </div>
      
      <div class="card-footer">
      <center>
        <a href="poster_rkeu30EtvS.html" class="btn btn-primary">Visit</a>
        </center>

      </div>
      <!-- </div> -->

  </div>
  
    </DIV>
          </DIV>
      </DIV>

</body>