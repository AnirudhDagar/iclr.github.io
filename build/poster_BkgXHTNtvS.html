<!doctype html>
<html lang="en">
  <head>
    <!-- Required meta tags -->
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

    <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css" integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous">
    <title> ICLR: Bounds on Over-Parameterization for Guaranteed Existence of Descent Paths in Shallow ReLU Networks </title>
</head>

  <body >
    
<!-- NAV -->

<script src="https://cdn.jsdelivr.net/npm/popper.js@1.16.0/dist/umd/popper.min.js" integrity="sha384-Q6E9RHvbIyZFJoft+2mJbHaEWldlvI9IOYy5n3zV9zzTtmI3UksdQRVvoxMfooAo" crossorigin="anonymous"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.4.1/js/bootstrap.min.js" integrity="sha384-wfSDF2E50Y2D1uUdj0O3uMBJnjuUD4Ih7YwaYd1iqfktj0Uod8GCExl3Og8ifwB6" crossorigin="anonymous"></script>
<link href="https://fonts.googleapis.com/css?family=Lato:400,900&display=swap" rel="stylesheet">

<style>
    body{font-family: 'Lato', sans-serif;}
</style>

<nav class="navbar navbar-expand-lg navbar-light bg-light mr-auto">
  <a class="navbar-brand" href="#">
    <img class="logo" src="https://www.iclr.cc/static/admin/img/ICLR-logo.png"  height="35"/>
  </a>
  <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
    <span class="navbar-toggler-icon"></span>
  </button>
  <div class="collapse navbar-collapse" id="navbarNav">
    <ul class="navbar-nav">
      <li class="nav-item active">
        <a class="nav-link" href="index.html">Home</a>
      </li>
      <li class="nav-item">
        <a class="nav-link" href="livestream.html">Live Stream</a>
      </li>
      <li class="nav-item">
        <a class="nav-link" href="papers.html">Papers</a>
      </li>

      <li class="nav-item">
        <a class="nav-link" href="paper_vis.html">PaperVis</a>
      </li>










      </ul>
</div>
  </div>
</nav>


<div class="container">
  
 <!-- Title -->

<div class="card" >
  <div class="card-body">
    <h3 class="card-title">Bounds on Over-Parameterization for Guaranteed Existence of Descent Paths in Shallow ReLU Networks</h3>
    <h6 class="card-subtitle mb-2 text-muted">
      Arsalan Sharifnassab,
      
      Saber Salehkaleybar,
      
      S. Jamaloddin Golestani,
      
    </h6>
    <p class="card-text"><span class="font-weight-bold">TL;DR:</span> We study the landscape of squared loss in neural networks with one-hidden layer and ReLU activation functions.  Let $m$ and $d$ be the widths of hidden and input layers, respectively. We show that there exist poor local minima with positive curvature...</p>
    <p class="card-text"><span class="font-weight-bold">Abstract:</span> We study the landscape of squared loss in neural networks with one-hidden layer and ReLU activation functions.  Let $m$ and $d$ be the widths of hidden and input layers, respectively. We show that there exist poor local minima with positive curvature for some training sets of size $n\geq m+2d-2$. By positive curvature of a local minimum, we mean that within a small neighborhood the loss function is strictly increasing in all directions. Consequently, for such training sets, there are initialization of weights from which there is no descent path to global optima. It is known that for $n\le m$, there always exist descent paths to global optima from all initial weights. In this perspective, our results provide a somewhat sharp characterization of the over-parameterization required for &#34;existence of descent paths&#34; in the loss landscape. </p>
    
    <center>
      <a class="card-link"  href="http://www.openreview.net/pdf/a496438e9fc64857be96ece516c0dcaa60d48b60.pdf">Paper</a>
      <a class="card-link"  href="http://www.openreview.net/forum?id=BkgXHTNtvS">OpenReview</a>
    <!-- <span><a href="" class="btn btn-secondary">OpenReview</a></span> -->

      <a href="" class="card-link">Code</a>
      <a href="" class="card-link">Slides</a>
    </center>
    <p></p>
    <p class="card-text"><span class="font-weight-bold">Keywords:</span>
      
      <a href="keyword_Spurious local minima.html" class="text-secondary text-decoration-none">Spurious local minima</a>,
      
      <a href="keyword_Loss landscape.html" class="text-secondary text-decoration-none">Loss landscape</a>,
      
      <a href="keyword_Over-parameterization.html" class="text-secondary text-decoration-none">Over-parameterization</a>,
      
      <a href="keyword_Theory of deep learning.html" class="text-secondary text-decoration-none">Theory of deep learning</a>,
      
      <a href="keyword_Optimization.html" class="text-secondary text-decoration-none">Optimization</a>,
      
      <a href="keyword_Descent path.html" class="text-secondary text-decoration-none">Descent path</a>,
      
    </p>    
  </div>
</div>

<div>
</div>

</div>


<!-- SlidesLive -->
<div id="presentation-embed-38915748" class="container container-sm"></div>
<script src='https://slideslive.com/embed_presentation.js'></script>
<script>
  embed = new SlidesLiveEmbed('presentation-embed-38915748', {
        presentationId: '38915748',
        autoPlay: false, // change to true to autoplay the embedded presentation
        verticalEnabled: true
    });
</script>


<!-- Buttons -->
<div  class="container" style="padding-bottom: 30px; padding-top:30px">
<!--   <center> -->
<!--     <span><a href="poster_.html" class="btn btn-secondary">Prev</a></span> -->

<!--     <span><a href="" class="btn btn-secondary">Video Call</a></span> -->

<!--     <span><a href="poster_.html" class="btn btn-secondary">Next</a></span> </center> -->
<!-- </div> -->
<!--   <center> -->
<center>
    <h2> Paper Discussion       </h2>
    <span><a class="btn btn-secondary" href="https://gitter.im/iclr/posterBkgXHTNtvS/">Chat</a></span>
</center>
<p></p>
<!-- Gitter -->
<div id="gitter" class="gitter container" height="600px">
  <center>
    <div class="border">
      <center> <iframe frameborder="0" src="https://gitter.im/iclr/posterBkgXHTNtvS/~embed" width="900px" height="400px"></iframe> </center>
    </div>
  </center>
</div>

<!-- Recs -->
<p></p>
<div  class="container" style="padding-bottom: 30px; padding-top:30px">
  <center>
    <h2> Similar Papers </h2>
</div>
<p></p>

<div  class="container" >
  <div class="row">
    <div class="card-deck">

      
      
  <!-- <div class="col-sm-4" style="padding-bottom: 10px"> -->
  <div class="card" >
    <div class="card-header">
        <a href="poster_HJxEhREKDH.html" class="text-dark"><h5 class="card-title">On the Global Convergence  of Training Deep Linear ResNets</h5></a>      

    </div>
      <div class="card-body">
        <p class="card-text"> Under certain condition on the input and output linear transformations, both GD and SGD can achieve global convergence for training deep linear ResNets.</p>
      </div>
      
      <div class="card-footer">
      <center>
        <a href="poster_HJxEhREKDH.html" class="btn btn-primary">Visit</a>
        </center>

      </div>
      <!-- </div> -->

  </div>
  
      
  <!-- <div class="col-sm-4" style="padding-bottom: 10px"> -->
  <div class="card" >
    <div class="card-header">
        <a href="poster_B1gX8kBtPr.html" class="text-dark"><h5 class="card-title">Universal Approximation with Certified Networks</h5></a>      

    </div>
      <div class="card-body">
        <p class="card-text"> We prove that for a large class of functions f there exists an interval certified robust network approximating f up to arbitrary precision.</p>
      </div>
      
      <div class="card-footer">
      <center>
        <a href="poster_B1gX8kBtPr.html" class="btn btn-primary">Visit</a>
        </center>

      </div>
      <!-- </div> -->

  </div>
  
      
  <!-- <div class="col-sm-4" style="padding-bottom: 10px"> -->
  <div class="card" >
    <div class="card-header">
        <a href="poster_B1guLAVFDB.html" class="text-dark"><h5 class="card-title">Span Recovery for Deep Neural Networks with Applications to Input Obfuscation</h5></a>      

    </div>
      <div class="card-body">
        <p class="card-text"> We provably recover the span of a deep multi-layered neural network with latent structure and empirically apply efficient span recovery algorithms to attack networks by obfuscating inputs.</p>
      </div>
      
      <div class="card-footer">
      <center>
        <a href="poster_B1guLAVFDB.html" class="btn btn-primary">Visit</a>
        </center>

      </div>
      <!-- </div> -->

  </div>
  
      
  <!-- <div class="col-sm-4" style="padding-bottom: 10px"> -->
  <div class="card" >
    <div class="card-header">
        <a href="poster_Skep6TVYDB.html" class="text-dark"><h5 class="card-title">Gradientless Descent: High-Dimensional Zeroth-Order Optimization</h5></a>      

    </div>
      <div class="card-body">
        <p class="card-text"> Gradientless Descent is a provably efficient gradient-free algorithm that is monotone-invariant and fast for high-dimensional zero-th order optimization.</p>
      </div>
      
      <div class="card-footer">
      <center>
        <a href="poster_Skep6TVYDB.html" class="btn btn-primary">Visit</a>
        </center>

      </div>
      <!-- </div> -->

  </div>
  
    </DIV>
          </DIV>
      </DIV>

</body>